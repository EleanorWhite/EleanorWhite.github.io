---
layout: post
title: HDR Photography
---

This last week in Physics of Photography core lab, I wrote a simple HDR software in Matlab.

HDR, or high dynamic range, is a technique for making photographs of images with a large range of brightness. HDR works by taking a photo of the same image at different exposure levels, and then superimposing them. This way, the brighter parts of the image will be exposed properly in the photo with less exposure, and the darker parts will be exposed in the photo with more exposure. 

This technique works well for creating an image with a high dynamic range, but most screens cannot actually portray much dynamic range. To solve this, HDR software uses a technique called tone-mapping. Tone mapping is taking an HDR photograph and mapping the tones back in to a dynamic range that a computer can display.

There are two broad ways to do tone-mapping, globally and locally. In global tone mapping, the software changes the amount of brightness the same amount everywhere in the image, so the bright parts will still be substantially brighter than the dark parts. This often creates images that do not look great, because there is not as much discernible detail. A solution to this is local tone-mapping, where the software maps the brightness so that there is a large amount of contrast in all parts of the image. This means that the brighter and darker parts of the image look closer to each other in terms of brightness, but individual details are more visible. As of right now, the software I wrote only uses global tone-mapping. 
'
I tested this program using a photo of a doorway on Scripps University. The original set of photos looked like this:
![well exposed image](https://github.com/EleanorWhite/HDRPhotography/blob/master/IMG_3053.JPG)
![over exposed image](https://github.com/EleanorWhite/HDRPhotography/blob/master/IMG_3054.JPG)
![under exposed image](https://github.com/EleanorWhite/HDRPhotography/blob/master/IMG_3045.JPG)

It uses three different techniques for global tone-mapping. The first is to weight the photos relative to their brightness, so the brightest photo will have the most effect on the photo. That creates a photo that seems overexposed because the overexposed photo has the most effect on it. Using the technique on the set of doorway photos creates this photo:
![HDR biased bright](https://github.com/EleanorWhite/HDRPhotography/blob/master/DoorwayHDRBiasedBright.jpg)

A better implementation of this is to create an image where all of the component images are weighted equally. This creates a much more balanced image:
![HDR equal weight](https://github.com/EleanorWhite/HDRPhotography/blob/master/DoorHDREqualWeight.jpg)

Unfortunately, the sky in the equally weighted photo is still washed out, so I also tried weighting the photo more towards the underexposed photo. This creates a sky that is less blue, but the overall photo looks underexposed.
![HDR biased dark](https://github.com/EleanorWhite/HDRPhotography/blob/master/DoorwayHDRBiasedDark.jpg)
